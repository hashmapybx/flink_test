## StartupOptions 参数说明
### initial
会先基于查询读取表中现有的历史数据，然后在切换到binlog模式的最新位置开始读取新增
以及变化的数据
在第一次启动时对被监视的数据库表执行初始快照，并继续读取最新的binlog。

### latest
直接从binlog最新的位置开始读取数据，也就是启动连接器连接到了以后。
只从binlog的末尾读取，这意味着只有自连接器启动以来的更改。
### earliest
会从binlog开始的位置，从表开始创建读取表中的数据。
必须先开启某个库的某个表的binlog,然后再去建表，也是binlog必须要包含建表的
信息。

昨天测试的是数据insert的数据flink cdc捕捉不到数据

### Kafka端到端一致性需要注意的点：
- Flink任务需要开启checkpoint配置为CheckpointingMode.EXACTLY_ONCE
- Flink任务FlinkKafkaProducer需要指定参数Semantic.EXACTLY_ONCE
- Flink任务FlinkKafkaProducer配置需要配置transaction.timeout.ms 
checkpoint间隔（代码指定）<transaction.timeout.ms(默认是一个小时)<transaction.max.timeout.ms(默认为15分钟)
- 消费端在消费FlinkKafkaProducer的topic时需要指定isolation.level(默认为read_uncommitted)为read_committed


 " 'value.json.fail-on-missing-field' = 'false',\n" +
 " 'value.json.ignore-parse-errors' = 'true' \n" +


### KafkaSource
当Flink开启Checkpoint时，Kafka的offset会在Checkpoint的时候，把偏移量保存到状态后端(也会提交到kafka中一份)。 注意，在这个场景中，
Kafka设置的Properties 中的自动定期 offset 提交设置会被完全忽略。
注意：Kafka source 不依赖于 broker 上提交的位点来恢复失败的作业。提交位点只是为了上报 Kafka consumer 和消费组的消费进度，以在 broker 端进行监控。


FLink jdbc 写入mysql sink exactly_oncesink

```java

mapDataStream.addSink(JdbcSink.exactlyOnceSink(insert_sql,
                (ps, s) -> {

                ps.setString(1, s.getOrderId());
                                ps.setString(2, s.getTreatShopId());
                                ps.setString(3, s.getCustomerId());
                                ps.setInt(4, s.getStatus());
                                ps.setInt(5, s.getIsTaxInclusive());
                                ps.setDouble(6, s.getCharge());
                                ps.setDate(7, new Date(Long.valueOf(s.getCreateTime())));
                                ps.setDate(8, new Date(Long.valueOf(s.getAcceptTime())));
                                ps.setString(9, s.getScene());
                                ps.setString(10, s.getPartnerId());
                                ps.setString(11, s.getChannelSource());
                }, JdbcExecutionOptions.builder()
                        .withMaxRetries(0)
                        .build(),
                JdbcExactlyOnceOptions.builder()
                        .withTransactionPerConnection(true)
                        .build(),() -> {
                    MysqlXADataSource xaDataSource = new MysqlXADataSource();
                    xaDataSource.setUrl("jdbc:mysql://172.21.35.63:3306/zczqdb?characterEncoding=utf8&serverTimezone=GMT%2B8");
                    xaDataSource.setUser("qn_zczq");
                    xaDataSource.setPassword("Qn_zczq@2022");
                    return xaDataSource;
                }
                )).name("jdbc insert");
```



## 写入Mysql的操作
```java
//将map端的数据写入到mysql
        String insert_sql = "INSERT INTO general_order_top_10 (order_id, treat_shop_id, customer_id, status,is_tax_inclusive," +
                " charge,create_time, accept_time, scene, partner_id,channel_source) " +
                "values (?,?,?,?,?,?,?,?,?,?,?)";

        JdbcStatementBuilder<QianNanOrderT> jdbcStatementBuilder = new JdbcStatementBuilder<QianNanOrderT>() {
            @Override
            public void accept(PreparedStatement ps, QianNanOrderT s) throws SQLException {
                ps.setString(1, s.getOrderId());
                ps.setString(2, s.getTreatShopId());
                ps.setString(3, s.getCustomerId());
                ps.setInt(4, s.getStatus());
                ps.setInt(5, s.getIsTaxInclusive());
                ps.setDouble(6, s.getCharge());
                ps.setDate(7, new Date(Long.parseLong(s.getCreateTime())));
                ps.setDate(8, new Date(Long.parseLong(s.getAcceptTime())));
                ps.setString(9, s.getScene());
                ps.setString(10, s.getPartnerId());
                ps.setString(11, s.getChannelSource());
            }
        };
        JdbcConnectionOptions jdbcConnectionOptions = new JdbcConnectionOptions.JdbcConnectionOptionsBuilder()
                .withUrl("jdbc:mysql://172.21.35.63:3306/zczqdb?characterEncoding=utf8&serverTimezone=GMT%2B8")
                .withDriverName("com.mysql.cj.jdbc.Driver")
                .withUsername("qn_zczq")
                .withPassword("Qn_zczq@2022")
                .build();

        JdbcExecutionOptions executionOptions = JdbcExecutionOptions.builder()
                .withBatchSize(1000)
                .withBatchIntervalMs(200)
                .withMaxRetries(5)
                .build();

//        mapDataStream.addSink(JdbcSink.sink(insert_sql, jdbcStatementBuilder, executionOptions, jdbcConnectionOptions));

//        filterDataStream.setParallelism(1)
//                .print("消费：").setParallelism(1);
        //需要写UDF来解析json格式数据
```




flink run 命令的相关参数
- 一、flink run参数：
flink run命令执行模板：flink run [option]

-c,–class : 需要指定的main方法的类

-C,–classpath : 向每个用户代码添加url，他是通过UrlClassLoader加载。url需要指定文件的schema如（file://）

-d,–detached : 在后台运行

-p,–parallelism : job需要指定env的并行度，这个一般都需要设置。

-q,–sysoutLogging : 禁止logging输出作为标准输出。

-s,–fromSavepoint : 基于savepoint保存下来的路径，进行恢复。

-sae,–shutdownOnAttachedExit : 如果是前台的方式提交，当客户端中断，集群执行的job任务也会shutdown。

- 二、flink run -m yarn-cluster参数
-m,–jobmanager : yarn-cluster集群
-yd,–yarndetached : 后台
-yjm,–yarnjobManager : jobmanager的内存
-ytm,–yarntaskManager : taskmanager的内存
-yn,–yarncontainer : TaskManager的个数
-yid,–yarnapplicationId : job依附的applicationId
-ynm,–yarnname : application的名称
-ys,–yarnslots : 分配的slots个数

例：flink run -m yarn-cluster -yd -yjm 1024m -ytm 1024m -ynm -ys 1

- 三、flink-list
flink list：列出flink的job列表。

flink list -r/–runing :列出正在运行的job

flink list -s/–scheduled :列出已调度完成的job

- 四、flink cancel
flink cancel [options] <job_id> : 取消正在运行的job id

flink cancel -s/–withSavepoint <job_id> ： 取消正在运行的job，并保存到相应的保存点

通过 -m 来指定要停止的 JobManager 的主机地址和端口

例： bin/flink cancel -m 127.0.0.1:8081 5e20cb6b0f357591171dfcca2eea09de

- 五、flink stop :仅仅针对Streaming job
flink stop [options] <job_id>

flink stop <job_id>：停止对应的job

通过 -m 来指定要停止的 JobManager 的主机地址和端口

例： bin/flink stop -m 127.0.0.1:8081 d67420e52bd051fae2fddbaa79e046bb

取消和停止（流作业）的区别如下：

cancel() 调用，立即调用作业算子的 cancel() 方法，以尽快取消它们。如果算子在接到 cancel() 调用后没有停止，Flink 将开始定期中断算子线程的执行，直到所有算子停止为止。
stop() 调用，是更优雅的停止正在运行流作业的方式。stop() 仅适用于 Source 实现了 StoppableFunction 接口的作业。当用户请求停止作业时，作业的所有 Source 都将接收 stop() 方法调用。直到所有 Source 正常关闭时，作业才会正常结束。这种方式，使作业正常处理完所有作业。
- 六、 flink modify 修改任务并行度
flink modify <job_id> [options] <br>

flink modify <job_id> -p /–parallelism p : 修改job的并行度 <br>

例： flink modify -p 并行数 <job_pid> <br>

- 七、flink savepoint <br>
flink savepoint [options] <job_id> <br>

eg: # 触发保存点 <br>

flink savepoint <job_id> hdfs://xxxx/xx/x : 将flink的快照保存到hdfs目录 <br>


使用yarn触发保存点 <br>

flink savepoint <job_id> <target_directory> -yid <application_id> <br>

使用savepoint取消作业 <br>

flink cancel -s <tar_directory> <job_id> <br>
从保存点恢复 <br>

flink run -s <target_directoey> [:runArgs] <br>

如果复原的程序，对逻辑做了修改，比如删除了算子可以指定allowNonRestoredState参数复原。  


flink run -s <target_directory> -n/–allowNonRestoredState [:runArgs] <br>

savepoint 与 checkpoint 的区别 <br>

checkpoint是增量做的，每次的时间短，数据量小，只要在程序里面启用后会自动触发，用户无需感知；savepoint是全量做的，时间长，数据量大，需要用户主动触发。<br>

checkpoint 是作业failover 的时候自动使用，不需要用户指定，savepoint 一般用于程序版本更新、bug修复、A/B Test 等场景，需要用户指定。 <br>


### kafka auto.offset.reset 参数说明
- latest 默认
- earliest
- None

-- 同一个消费组，多个消费者 latest <br>
对于同一个消费者组，若是已经提交过的offset，则是从最新的offset开始消费数据，新启动的消费者只会从最新的offset开始消费<br>

earliest还是会从最早的Offset消费数据<br>

不同消费组 latest <br>
新启动一个消费者，也是从最新的开始消费数据, <br>
earliest还是会从最早的位置开始消费数据 <br>

### FLink run 作业
- FLink yarn-per-job提交 <br>
./flink run -m clusetr-yarn -yjm 1024 -ytm 1024 -yd -ynm cdc_kafka -ys 4 /etl/flink_yiliao-1.0-SNAPSHOT.jar <br>
中间手动定期做savepoint <br>
./flink savepoint e423ef2e617fd30ff9431d022fb7f0f9 hdfs://drmcluster/flink/sck/  -t yarn-session -Dyarn.application.id=application_1672383773206_33762 <br>

当作业失败的话，从savepoint来恢复<br>
./flink run -s hdfs://drmcluster/flink/sck/savepoint-e423ef-0aa04f0b906f/_metadata /etl/flink_yiliao-1.0-SNAPSHOT.jar <br>
- FLink run yarn-session 模式<br>
先启动uyarn-session<br>
在flink run 提交作业 <br>


### CDC踩坑
1、mysql时区问题 需要在代码里面手动处理
2、ck文件覆盖写的问题
3、在手动yarn kill 掉cdc的作业时候，checkpoint的文件会自动被清理掉。只能是从savepoint的文件来恢复
4、cdc在采集数据的时候解决断点续传的问题。假如在同步数据需要一天的时间，在作业线上运行10个小时失败了。不需要重新跑整个数据同步任务，
只需要从发生错误的位置开始重新跑作业就好了。
5. flink checkpooint 底层都是异步执行操作。从FLInk 1.11开始就是允许进行barrier对齐和不对齐的操作
6. 测试Flink 异常是否会发生ck保存成功 设计一个代码


## CdC 测试msyql binlog到kafka数据重复的问题
解决方案：
1.cdc 第一次全量之后，需要手动判断全量完成之后，人工去执行savepoint操作.  

其中savepoint触发方式：<br>
（1）bin/flink savepoint :jobId [:targetDirectory] <br>
（2）$ bin/flink savepoint --type [native/canonical] :jobId [:targetDirectory] 指定savepoint文件的格式。默认是标准格式 <br>
（3）使用Yarn来触发，$ bin/flink savepoint :jobId [:targetDirectory] -yid :yarnAppId  <br>

./flink savepoint <flink web job id> hdfs://drmcluster/flink/sck/ <savepoint文件路径>  -t yarn-session -Dyarn.application.id=对应的yarn上面的appID  

2、在将yarn的job kill掉  
yarn application -kill application_1672383773206_34076<appID>

3.在二次重启之前提价的jar包<br>
./flink run -s hdfs://drmcluster/flink/sck/savepoint-e423ef-0aa04f0b906f/_metadata /etl/flink_yiliao-1.0-SNAPSHOT.jar

4.通过在 flink 监控 web页面的logout可以看到确实解决了之前重复从earliest全量同步数据。

## checkpoint文件个数  
// 目前代码不能设置保留的checkpoint个数 默认值时保留一个 假如要保留3个
// 可以在flink-conf.yaml中配置 state.checkpoints.num-retained: 3

修改配置文件生效，记得先做savepoint在开始kill作业在重启作业.
savepoint  hdfs://drmcluster/flink/scdc/savepoint-ed6652-ddeacc6ffbfb


-- kafka压测脚本 
kafka-producer-perf-test.sh --throughput 10000 --record-size 5000 --num-records 10000 --topic crm11 --print-metrics --producer-props bootstrap.servers=hbe3base14:9092


## flink 配置火焰图追踪堆栈的信息

火焰图主要是用来跟踪堆栈线程重复多次采样而生成的，每个方法的调用表示为一个长方形，长方形的长度和在采样中出现的次数成正比。
### 图的解释;
- y轴: 表示调用栈，每一层都是一个函数，调用栈越深。火焰的颜色越高，顶部就是正在执行的函数，下方都是父函数。
- x轴： 表示的是抽样数，如果一个函数在x轴占据的函数宽度越宽，表示该函数在抽样到的次数就是越多，既是执行时间长。

火焰图主要是看顶部的哪个函数占据的宽度最大，表示该函数可能存在性能问题。

### 火焰图分类：
- ON-CPU：基于线程在CPu上执行消耗的时间采样，查看线程在CPu上花费的时间，
- OFF-CPU：基于线程在CPU上（IO,锁，中断等原因）上消耗的时间。可以直观的查看线程花费在阻塞上的时间分布

### 具体的配置信息：在flink-conf.yml文件中配置
- rest.flamegraph.enabled： 默认值: false 说明：是否开启火焰图
- rest.flamegraph.cleanup-interval 默认值：10min 说明：统计信息的缓存清除时间
- rest.flamegraph.delay-between-samples 默认值：50 ms 说明：构建 FlameGraph 的单个堆栈跟踪样本之间的延迟。
- rest.flamegraph.num-samples 默认值：100 构建flamegraph的采样数
- rest.flamegraph.refresh-interval 默认值：1min 说明：火焰图刷新的时间间隔
- rest.flamegraph.stack-depth 默认值：100 说明：创建FlameGraphs 的堆栈跟踪的最大深度 


## FLink 里面的trigger

触发器定义了窗口会在何时求值以及何时发送结果数据，默认的触发器会在下面两种情况下发生：  
1、处理时间（processing Time）机器时间到达处理时间  
2、事件时间（EventTime）水位线超过了窗口的结束时间就会触发

触发器可以访问流的时间属性以及定时器，还可以对state状态编程。
所以触发器和process function一样强大。例如我们可以实现一个触发逻辑：当窗口接收到一定数量的元素时，触发器触发。
再比如当窗口接收到一个特定元素时，触发器触发。还有就是当窗口接收到的元素里面包含特定模式(5秒钟内接收到了两个同样类型的事件)，触发器也可以触发。
在一个事件时间的窗口中，一个自定义的触发器可以提前(在水位线没过窗口结束时间之前)计算和发射计算结果。
这是一个常见的低延迟计算策略，尽管计算不完全，但不像默认的那样需要等待水位线没过窗口结束时间。

### FLink内部预置的触发器：
- EventTimeTrigger:
通过比对EvntTime和窗口的endTime确定是否触发窗口计算，如果EventTime大于window endTime则会触发，否则不会触发，一直等待。
- ProcessTimeTrigger
通过比对ProcessingTime和window endtime确实，如果processingTime大于窗口的endTime则会触发，否则一直等到
- ContinuousEventTimeTrigger：
根据间隔时间周期性触发，或者是window的结束时间小于当前eventTime触发计算
- ContinuousProcessingTimeTrigger
根据间隔时间周期性触发，或者是window的结束时间小于当前processTime触发计算
- CountTrigger
根据接入数据量是否大于设置的阈值来判断是否触发计算。
- DeltaTrigger
根据接入数据计算一个指标值，是否超过指定的Threshold去判断是否触发窗口计算。来判断是否触发
- PurgingTrigger
可以将任意触发器作为参数转换为Purge类型的触发器，计算完成后数据将被清理
- NeverTrigger
任何时候都不触发

**需要注意点**  

1、在EventTime时间语义下，必须定义watermark，那么trigger的触发时间=event time+watermark延迟时间。比如：eventtimeTrigger在设置有watermark的情况下，只有eventtime加上watermark是延迟时间大于window endTime触发窗口计算。  

2、像GlobalWindows默认是neverTrigger，所以在使用的时候一般要配合触发器使用。











 



